{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于CrawlSpider的全站爬取\n",
    "- CrawlSpider是爬虫类Spider的一个子类\n",
    "- 使用流程：\n",
    "    - 1.创建一个基于CrawlSpider的爬虫文件：scrapy genspider -t crawl 爬虫文件名称 www.xxx.com\n",
    "    - 2.构造链接提取器和规则解析器\n",
    "        - 链接提取器：\n",
    "            - 作用：根据指定规则进行指定链接提取\n",
    "            - 提取规则：allow='正则表达式'\n",
    "        - 规则解析器：\n",
    "            - 作用：获取链接提取器取到的链接，然后对其进行请求发送，根据指定规则对请求到的页面源码数据进行解析\n",
    "        - follow=True：将链接提取器继续作用到链接提取器提取出的URL对应的页面中\n",
    "\n",
    "### 分布式\n",
    "- 什么是分布式？\n",
    "    - 基于多台计算机组建一个分布式集群，然后使集群中的每一台计算机执行同一组程序，让它们对同一个网站的数据进行分布爬取\n",
    "- 为什么使用分布式爬虫？\n",
    "    - 提升爬取数据效率\n",
    "- 如何实现分布式爬虫？\n",
    "    - 基于scrapy+redis实现分布式\n",
    "        - scrapy结合scrapy-redis组件实现分布式\n",
    "- 原生的scrapy框架无法实现分布式\n",
    "    - 调度器无法被集群共享\n",
    "    - 管道无法被共享\n",
    "- scrpay-redis组件作用：提供可以被共享的调度器和管道\n",
    "- 环境安装：\n",
    "    - redis\n",
    "    - pip install scrapy-redis\n",
    "- 流程：\n",
    "    - 1.创建一个工程\n",
    "    - 2.创建一个爬虫文件：基于CrawlSpider的爬虫文件\n",
    "        - 修改当前爬虫文件\n",
    "            - 导包：from scrapy_redis.spiders import RedisCrawlSpider\n",
    "            - 将start_urls替换成redis_key = 'XXX'，共享调度器的队列名称\n",
    "            - 编写爬虫类爬取数据操作\n",
    "        - 修改settings.py文件\n",
    "            - 开启可以被共享的管道：ITEM_PIPELINES = { 'scrapy_redis.pipelines.RedisPipeline': 400, }\n",
    "            - 去重容器：DUPEFILTER_CLASS =\"scrapy_redis.dupefilter.RFPDupeFilter\"\n",
    "            - 指定共享调度器：SCHEDULER = \"scrapy_redis.scheduler.Scheduler\"\n",
    "            - 实现增量式爬取：SCHEDULER_PERSIST=True\n",
    "            - 指定redis服务：REDIS_HOST = '本机ip'，REDIS_PORT = 6379\n",
    "        - redis的配置文件（redis.windows.conf）进行修改：\n",
    "            - bind 127.0.0.1：进行注释\n",
    "            - protected-mode no：分布式集群中的其他计算机可以进行写入数据\n",
    "            - 我们使用redis版本：2.8，可以不进行设计保护模式。原因如下：Redis从3.2开始加强安全管理，如果redis没有设置密码，那么redis客户端只能从本地进行访问，如果是从其他机器连接过来访问的，就会报错误。\n",
    "        - 携带配置文件启动redis服务：redis-server .\\redis.windows.conf\n",
    "        - 启动redis客户端\n",
    "        - 执行当前工程：\n",
    "            - 1. 进入爬虫文件对应目录下，执行命令：scrapy runspider xxx.py\n",
    "            - 2. 向调度队列中扔入一个起始url：\n",
    "                - 队列在哪？队列在redis中\n",
    "                - lpush fbsQueue www.xxx.com\n",
    "\n",
    "### 增量式爬虫\n",
    "- 概念：监测网站数据更新情况\n",
    "- 核心：去重\n",
    "- 深度爬取类型的网站中需要对详情页的url进行记录和检测\n",
    "    - 记录：将爬取过的详情页的url进行记录保存；存储到redis的set中\n",
    "    - 检测：若对某一个详情页的url发起请求之前，先要去记录表中进行查看，该url是否存在。若存在，则被爬取过\n",
    "\n",
    "- 非深度爬取类型的网站：\n",
    "    - 名词：数据指纹。一组数据的唯一标识\n",
    "    - 使用md5等方式实现\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
