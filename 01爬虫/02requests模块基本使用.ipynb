{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- request模块\n",
    "    - 概念：一个基于网络请求的模块，用来模拟浏览器发起请求\n",
    "    - 编码流程：\n",
    "        - 指定url\n",
    "        - 进行请求的发送\n",
    "        - 获取响应数据（爬取到的数据）\n",
    "        - 持久化存储\n",
    "            - 环境安装：pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 爬取搜狗首页对应的页面源码数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# https://www.sogou.com/\n",
    "url = r\"https://www.sogou.com/\"\n",
    "# 发起请求，返回值是一个Response对象\n",
    "res = requests.get(url)\n",
    "# 返回字符串形式的数据\n",
    "page_text = res.text\n",
    "# 存储数据\n",
    "with open(r\"./Sougou.html\",\"w\",encoding=\"utf8\") as f:\n",
    "    f.write(page_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基于搜狗编写一个简易的网页采集器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a keyword周杰伦\n"
     ]
    }
   ],
   "source": [
    "# 将url携带的参数设定成动态变化\n",
    "url = r\"https://www.sogou.com/web\"\n",
    "# 存储动态的请求参数\n",
    "wd = input(\"Enter a keyword\")\n",
    "params = {\n",
    "    \"query\": wd\n",
    "}\n",
    "# 将params作用到请求中\n",
    "# params参数：对请求url参数的封装\n",
    "res = requests.get(url,params=params)\n",
    "res.encoding = \"utf-8\"\n",
    "page_text = res.text\n",
    "with open(\"./searchResult.html\",\"w\",encoding=\"utf8\") as f:\n",
    "    f.write(page_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 反爬机制：User-Agent\n",
    "- 反反爬机制：UA伪装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a keyword周杰伦\n",
      "爬取完成！\n"
     ]
    }
   ],
   "source": [
    "# 将url携带的参数设定成动态变化\n",
    "url = r\"https://www.sogou.com/web\"\n",
    "# 存储动态的请求参数\n",
    "wd = input(\"Enter a keyword\")\n",
    "params = {\n",
    "    \"query\": wd\n",
    "}\n",
    "# 请求头信息\n",
    "headers = {\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\"\n",
    "}\n",
    "# 将params作用到请求中\n",
    "# params参数：对请求url参数的封装\n",
    "# headers 参数：实现UA伪装\n",
    "res = requests.get(url,params=params,headers=headers)\n",
    "res.encoding = \"utf-8\"\n",
    "page_text = res.text\n",
    "with open(\"./searchResult.html\",\"w\",encoding=\"utf8\") as f:\n",
    "    f.write(page_text) \n",
    "print(\"爬取完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 爬取豆瓣电影详情数据\n",
    "    - 分析：当滚轮滑动到底部时，发起了一个Ajax请求，且该请求到了一组电影数据\n",
    "- 动态加载数据：通过另一个额外的请求去请求到的数据\n",
    "    - Ajax请求生产动态加载数据\n",
    "    - js生成动态加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入开始编号：10\n",
      "请输入搜索范围：30\n",
      "爬取成功\n"
     ]
    }
   ],
   "source": [
    "# 链接参数：type=5&interval_id=100%3A90&action=&start=0&limit=20\n",
    "url = r\"https://movie.douban.com/j/chart/top_list\"\n",
    "\n",
    "# 输入\n",
    "start = input(\"请输入开始编号：\")\n",
    "limit = input(\"请输入搜索范围：\")\n",
    "\n",
    "# 参数\n",
    "params = {\n",
    "    \"type\":5,\n",
    "    \"interval_id\":\"100:90\",\n",
    "    \"action\":\"\",\n",
    "    \"start\":start,\n",
    "    \"limit\":limit\n",
    "}\n",
    "# 定义headers，模拟User-Agent\n",
    "headers = {\n",
    "    \"User-Agent\":r\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"\n",
    "}\n",
    "response = requests.get(url,params=params,headers=headers)\n",
    "response.encoding = \"utf8\"\n",
    "\n",
    "# json返回的是序列化好的对象\n",
    "fp = open(\"./movie.txt\",\"w+\",encoding=\"utf8\")\n",
    "data_list = response.json()\n",
    "for dic in data_list:\n",
    "    title = dic[\"title\"]\n",
    "    score = dic[\"score\"]\n",
    "    fp.write(title+\":\"+score+\"\\n\")\n",
    "fp.close()\n",
    "print(\"爬取成功\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 爬取肯德基餐厅位置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入城市：北京\n",
      "['\"addressDetail\":\"小营东路3号北京凯基伦购物中心一层西侧\"', '\"addressDetail\":\"朝阳路杨闸环岛西北京通苑30号楼一层南侧\"', '\"addressDetail\":\"黄寺大街15号北京城乡黄寺商厦\"', '\"addressDetail\":\"西四环北路117号北京欧尚超市F1、B1\"', '\"addressDetail\":\"北京经济开发区西环北路18号F1＋F2\"', '\"addressDetail\":\"通顺路石园西区南侧北京顺义西单商场石园分店一层、二层部分\"', '\"addressDetail\":\"北京南站候车大厅B岛201号\"', '\"addressDetail\":\"北京北清路1号146区\"', '\"addressDetail\":\"海户屯北京新世纪服装商贸城一层南侧\"', '\"addressDetail\":\"巴沟路2号北京华联万柳购物中心一层\"']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=keyword\n",
    "# keyword: 城市\n",
    "city = input(\"请输入城市：\")\n",
    "post_url = r\"http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=keyword\"\n",
    "data = {\n",
    "    \"cname\":\"\",\n",
    "    \"pid\":\"\",\n",
    "    \"keyword\":city,\n",
    "    \"pageIndex\":\"1\",\n",
    "    \"pageSize\":\"10\"\n",
    "}\n",
    "# 定义headers，模拟User-Agent\n",
    "headers = {\n",
    "    \"User-Agent\":r\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"\n",
    "}\n",
    "# data参数：表示get()方法中的params参数\n",
    "response = requests.post(post_url,data,headers=headers)\n",
    "kfc_data = response.text\n",
    "# print(kfc_data)\n",
    "# 使用re模块获取数据\n",
    "dataList = re.findall(r'\"addressDetail\":\".*?\"',kfc_data)\n",
    "print(dataList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何判定一张页面中是否存在动态加载数据?\n",
    "- 抓包工具进行局部搜索\n",
    "- 若判定出页面中有动态加载的数据,如何进行数据定位?\n",
    "    - 使用抓包工具进行全局搜索\n",
    "- 对一个陌生的网站数据进行爬取前,要判断爬取的数据是否为动态加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 爬取药监总局化妆品许可证数据(http://scxk.nmpa.gov.cn:81/xk/)\n",
    "    - 分析:\n",
    "        - 1. 网站首页和企业的详情页数据都是动态加载\n",
    "        - 2. 分析某一家企业详情数据是怎么来的\n",
    "            - 企业详情数据是通过一个Ajax请求(post)请求到的\n",
    "            - 请求对应url:http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsById\n",
    "            - 该请求携带了参数:id:d80612543cd9413b84e7525d771cee5f\n",
    "            - 结论:\n",
    "                - 1.每家企业都是post形式的Ajax请求到的\n",
    "                - 2.每家企业对应的Ajax请求的url都一样,请求方式都是post,只有请求参数id的值不一样\n",
    "                - 3.需要获取每一家企业的id值,即可获取每一家企业对应的详情数据\n",
    "        - 3. 需要获取每家企业的id值\n",
    "            - 思路;每一家企业的id值应该在首页对应相关请求或响应中\n",
    "                 首页请求url:http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsList\n",
    "                 参数:on: true\n",
    "                    page: 1\n",
    "                    pageSize: 15\n",
    "                    productName: \n",
    "                    conditionType: 1\n",
    "                    applyname: \n",
    "                    applysn: \n",
    "            - 结论:每一家企业的id值,存储在首页中的某一个Ajax请求对应的响应中,需要将该响应数据中的id值提取出来即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每一家企业的id\n",
    "url = r\"http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsList\"\n",
    "data = {\n",
    "    \"on\": \"true\",\n",
    "    \"page\": \"1\",\n",
    "    \"pageSize\": \"15\",\n",
    "    \"productName\": \"\",\n",
    "    \"conditionType\": \"1\",\n",
    "    \"applyname\": \"\",\n",
    "    \"applysn\": \"\"\n",
    "}\n",
    "headers = {\n",
    "    \"User-Agent\":r\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"\n",
    "}\n",
    "# 每一家企业的id\n",
    "data_json = requests.post(url,data,headers=headers).json()\n",
    "data_list = data_json[\"list\"]\n",
    "fp = open(\"./companydata.txt\",\"w+\",encoding=\"utf8\")\n",
    "for l in data_list:\n",
    "    com_id = l[\"ID\"]\n",
    "    # print(com_id)\n",
    "    post_url = r\"http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsById\"\n",
    "    post_data = {\n",
    "        \"id\":com_id\n",
    "    }\n",
    "    res = requests.post(post_url,post_data,headers=headers)\n",
    "    details = res.json()\n",
    "    companyName = details[\"epsName\"]\n",
    "    companyAddress = details[\"epsAddress\"]\n",
    "    fp.write(companyName+\":\"+companyAddress+\"\\n\")\n",
    "print(\"爬取完成\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 什么是抓包工具\n",
    "    - 代理服务器:进行请求转发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 作业:将药监总局前5页企业详情数据进行爬取,且进行任意形式的持久化存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爬取完成\n"
     ]
    }
   ],
   "source": [
    "indexUrl = r\"http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsList\"\n",
    "detailUrl = r\"http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsById\"\n",
    "headers = {\n",
    "    \"User-Agent\":r\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"\n",
    "}\n",
    "f = open(\"./practiceDrug.txt\",\"w+\",encoding=\"utf8\")\n",
    "for i in range(1,6):\n",
    "    indexData = {\n",
    "        \"on\":\"true\",\n",
    "        \"page\":i,\n",
    "        \"pageSize\":\"15\",\n",
    "        \"productName\":\"\",\n",
    "        \"conditionType\":\"1\",\n",
    "        \"applyname\":\"\",\n",
    "        \"applysn\":\"\"\n",
    "    }\n",
    "    dataList = requests.post(indexUrl,indexData,headers=headers).json()[\"list\"]\n",
    "    for ls in dataList:\n",
    "        companyId = ls[\"ID\"]\n",
    "        detailData = {\n",
    "            \"id\":companyId\n",
    "        }\n",
    "        details = requests.post(detailUrl,detailData,headers=headers).json()\n",
    "        companyName = details[\"epsName\"]\n",
    "        companyAddress = details[\"epsProductAddress\"]\n",
    "        f.write(companyName+\",\"+companyAddress+\"\\n\")\n",
    "f.close()\n",
    "print(\"爬取完成\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
