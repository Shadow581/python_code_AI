{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scrapy图片爬取\n",
    "    - 1. 在爬虫文件中，爬取图片地址（只需要爬取地址），封装至item对象中，提交item\n",
    "    - 2. 在pipelines.py文件中，写入 from scrapy.pipelines.images import ImagesPipeline\n",
    "    - 3. pipelines.py文件中，管道类继承ImagesPipeline类\n",
    "    - 4. 在管道类中，重写方法：\n",
    "        - get_media_requests()：对某一个资源进行请求发送\n",
    "        - file_path()：媒体数据存储的名称\n",
    "        - item_completed()：将item传递给下一个即将执行的管道类\n",
    "    - 5. 配置文件settings.py：\n",
    "        - 指定图片存储文件夹：IMAGES_STORE='./imgs'\n",
    "\n",
    "- 提升scrapy爬取文件效率：将下列步骤写入配置文件settings.py中\n",
    "    - 增加并发：默认scrapy开启的并发线程为32个，可以适当进行增加。在settings配置文件中修改CONCURRENT_REQUESTS = 100值为100,并发设             置成了为100。\n",
    "\n",
    "    - 降低日志级别：在运行scrapy时，会有大量日志信息的输出，为了减少CPU的使用率。可以设置log输出信息为INFO或者ERROR即可。在配置文                件中编写：LOG_LEVEL = ‘INFO’\n",
    "\n",
    "    - 禁止cookie：如果不是真的需要cookie，则在scrapy爬取数据时可以进制cookie从而减少CPU的使用率，提升爬取效率。在配置文件中编写：              COOKIES_ENABLED = False\n",
    "\n",
    "    - 禁止重试：对失败的HTTP进行重新请求（重试）会减慢爬取速度，因此可以禁止重试。在配置文件中编写：RETRY_ENABLED = False\n",
    "\n",
    "    - 减少下载超时：如果对一个非常慢的链接进行爬取，减少下载超时可以能让卡住的链接快速被放弃，从而提升效率。在配置文件中进行编写：                DOWNLOAD_TIMEOUT = 10 超时时间为10s\n",
    "\n",
    "- 请求传参\n",
    "    - 实现深度爬取：爬取多个层级对应的页面数据\n",
    "    - 使用场景：爬取的数据没有在同一张页面中\n",
    "    - 在手动请求时，传递item：yield scrapy.Request(url,callback,meta={\"item\":item})\n",
    "        - 将meta字典传递给callback\n",
    "        - 在callback中，接收item，item = response.meta['item']\n",
    "\n",
    "- scrapy中间件的应用\n",
    "    - 爬虫中间件，下载中间件\n",
    "    - 下载中间件：\n",
    "        - 作用：批量拦截请求和响应\n",
    "        - 拦截请求\n",
    "            - UA伪装：将所有请求尽可能多的设定为不同的请求载体身份标识\n",
    "                - request.headers[\"User-Agent\"] = \"XXX\"\n",
    "            - 代理操作\n",
    "                - request.meta[\"proxy\"] = \"XXX\"\n",
    "        - 拦截响应：修改响应数据或者直接替换响应对象\n",
    "    - selelnium在scrapy中应用\n",
    "        - 实例化浏览器对象：写在爬虫类的构造方法中\n",
    "        - 关闭浏览器：爬虫文件中：def closed(self,spider)\n",
    "        - 中间件中执行浏览器自动化操作\n",
    "\n",
    "- 需求：爬取网易新闻：国内、国际、数独、军事、航空这5个模块下的新闻标题和内容\n",
    "    - 分析：\n",
    "        - 1.每一个模块页面中新闻数据是动态加载\n",
    "        - 2.使用selenium进行处理\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
